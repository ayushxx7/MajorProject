{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B072LPF91D\n",
      "Downloading and processing page http://www.amazon.com/dp/B017HW9DEW\n"
     ]
    }
   ],
   "source": [
    "from lxml import html  \n",
    "import json\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "def ParseReviews(asin):\n",
    "    #This script has only been tested with Amazon.com\n",
    "    amazon_url  = 'http://www.amazon.in/dp/'+asin\n",
    "    # Add some recent user agent to prevent amazon from blocking the request \n",
    "    # Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "    page = requests.get(amazon_url,headers = headers).text\n",
    "\n",
    "    parser = html.fromstring(page)\n",
    "    XPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "    XPATH_REVIEW_SECTION = '//div[@id=\"revMHRL\"]/div'\n",
    "    XPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "    XPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "    XPATH_PRODUCT_PRICE  = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "\n",
    "    raw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "    product_price = ''.join(raw_product_price).replace(',','')\n",
    "\n",
    "    raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "    product_name = ''.join(raw_product_name).strip()\n",
    "    total_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "    reviews = parser.xpath(XPATH_REVIEW_SECTION)\n",
    "\n",
    "    ratings_dict = {}\n",
    "    reviews_list = []\n",
    "\n",
    "    #grabing the rating  section in product page\n",
    "    for ratings in total_ratings:\n",
    "        extracted_rating = ratings.xpath('./td//a//text()')\n",
    "        if extracted_rating:\n",
    "            rating_key = extracted_rating[0] \n",
    "            raw_raing_value = extracted_rating[1]\n",
    "            rating_value = raw_raing_value\n",
    "            if rating_key:\n",
    "                ratings_dict.update({rating_key:rating_value})\n",
    "\n",
    "    #Parsing individual reviews\n",
    "    for review in reviews:\n",
    "        XPATH_RATING  ='./div//div//i//text()'\n",
    "        XPATH_REVIEW_HEADER = './div//div//span[contains(@class,\"text-bold\")]//text()'\n",
    "        XPATH_REVIEW_POSTED_DATE = './/a[contains(@href,\"/profile/\")]/parent::span/following-sibling::span/text()'\n",
    "        XPATH_REVIEW_TEXT_1 = './/div//span[@class=\"MHRHead\"]//text()'\n",
    "        XPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "        XPATH_REVIEW_COMMENTS = './/a[contains(@class,\"commentStripe\")]/text()'\n",
    "        XPATH_AUTHOR  = './/a[contains(@href,\"/profile/\")]/parent::span//text()'\n",
    "        XPATH_REVIEW_TEXT_3  = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "        raw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "        raw_review_rating = review.xpath(XPATH_RATING)\n",
    "        raw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "        raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "        raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "        raw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "        raw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "        author = ' '.join(' '.join(raw_review_author).split()).strip('By')\n",
    "\n",
    "        #cleaning data\n",
    "        review_rating = ''.join(raw_review_rating).replace('out of 5 stars','')\n",
    "        review_header = ' '.join(' '.join(raw_review_header).split())\n",
    "        review_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "        review_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "        #grabbing hidden comments if present\n",
    "        if raw_review_text2:\n",
    "            json_loaded_review_data = json.loads(raw_review_text2[0])\n",
    "            json_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "            cleaned_json_loaded_review_data_text = re.sub('<.*?>','',json_loaded_review_data_text)\n",
    "            full_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "        else:\n",
    "            full_review_text = review_text\n",
    "        if not raw_review_text1:\n",
    "            full_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "        raw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "        review_comments = ''.join(raw_review_comments)\n",
    "        review_comments = re.sub('[A-Za-z]','',review_comments).strip()\n",
    "        review_dict = {\n",
    "                            'review_comment_count':review_comments,\n",
    "                            'review_text':full_review_text,\n",
    "                            'review_posted_date':review_posted_date,\n",
    "                            'review_header':review_header,\n",
    "                            'review_rating':review_rating,\n",
    "                            'review_author':author\n",
    "\n",
    "                        }\n",
    "        reviews_list.append(review_dict)\n",
    "\n",
    "    data = {\n",
    "                'ratings':ratings_dict,\n",
    "                'reviews':reviews_list,\n",
    "                'url':amazon_url,\n",
    "                'price':product_price,\n",
    "                'name':product_name\n",
    "            }\n",
    "    return data\n",
    "\n",
    "\n",
    "def ReadAsin():\n",
    "    #Add your own ASINs here \n",
    "    AsinList = ['B072LPF91D','B017HW9DEW']\n",
    "    extracted_data = []\n",
    "    for asin in AsinList:\n",
    "        print( \"Downloading and processing page http://www.amazon.com/dp/\"+asin)\n",
    "        extracted_data.append(ParseReviews(asin))\n",
    "        sleep(5)\n",
    "    f=open('data.json','w')\n",
    "    json.dump(extracted_data,f,indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ReadAsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to refund box Quality bad\n",
      "The product is a real deal. The battery life is amazing! I am very much satisfied with all the features of the phone.\n",
      "So far its good , I will update the rating and review incase something comes up!\n",
      "Lightning fast\n",
      "Mine i just 2 months and the screen though claimed to be gorilla glass, had few cracks with a 1 feet fall. fortunately the display is intact and have to use it like this now since screen is not covered by warranty. I was an mi lover and third mi phone this, but not any longer\n",
      "Beast under 20k phone. which can beat any Brand's phone in price bracket 30 k. You can check on YouTube all recommend this device\n",
      "Very nice mobile\n",
      "I have mobile\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "review class of Amazon -> cr-original-review-content\n",
    "\n",
    "## lets forget about how to get exact product link for a minute and focus on getting reviews first.\n",
    "https://www.amazon.in/dp/B072LPF91D <- iphone x\n",
    "'''\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# search = 'https://www.amazon.in/dp/B072LPF91D'\n",
    "search = 'https://www.amazon.in/Mi-Poco-64GB-Steel-Blue/dp/B07H4X4F5Y'\n",
    "\n",
    "review_list = []\n",
    "home_page = requests.get(search,headers=headers)\n",
    "home_content = home_page.content\n",
    "soup = bs(home_content, 'html.parser')\n",
    "# print(soup)\n",
    "for review in soup.findAll(\"div\", {\"class\": \"reviewText\"}):\n",
    "#     print(review)\n",
    "    print(review.text.strip())\n",
    "    review_list.append(review.text.strip())\n",
    "\n",
    "df = pd.DataFrame(review_list,columns = ['Reviews'])\n",
    "# df.to_csv('iPhone.csv',index = False)\n",
    "df.to_csv('reviews.csv',index=False)\n",
    "    \n",
    "# for review in soup.findAll(\"div\", {\"a\": \"review-title-content\"}):\n",
    "#     print(review.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def gsearch_to_amaazon_links(search_term = \"apple+iphone+x\"):\n",
    "    \n",
    "    amazon_url_list = []\n",
    "    g_search = 'https://www.google.com/search?&q=' + search_term + 'amazon'\n",
    "    response = requests.get(g_search)\n",
    "    \n",
    "    soup = bs(response.text,'html.parser')\n",
    "    results = soup.find_all('div', class_='g')\n",
    "\n",
    "    for result in results:\n",
    "\n",
    "        a_tag = result.find('a')\n",
    "\n",
    "    #     print(link['href'])\n",
    "\n",
    "        if '/dp/' in a_tag['href']:\n",
    "\n",
    "            link = a_tag['href']\n",
    "            url = link.split('=')\n",
    "            url = url[1].split('&')[0]\n",
    "            print(url)\n",
    "            amazon_url_list.append(url)\n",
    "    \n",
    "    return amazon_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/Xiaomi-Pocophone-Factory-Unlocked-Smartphone/dp/B07GZ4QJTS\n",
      "https://www.amazon.com/Xiaomi-Pocophone-Graphite-Unlocked-Warranty/dp/B07H41NB46\n",
      "https://www.amazon.in/Mi-Poco-64GB-Steel-Blue/dp/B07H4X4F5Y\n",
      "https://www.amazon.co.uk/Xiaomi-Pocophone-Dual-64GB-Blue/dp/B07GY6GVHF\n",
      "https://www.amazon.co.uk/Xiaomi-Pocophone-F1-Black-64GB/dp/B07GTD2XDF\n"
     ]
    }
   ],
   "source": [
    "# gsearch_to_amaazon_links('2 ton ka ac')\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(gsearch_to_amaazon_links('pocofone'),columns = ['Link'])\n",
    "df.to_csv('iPhone.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to refund box Quality bad'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "df['Reviews'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The product is a real deal. The battery life is amazing! I am very much satisfied with all the features of the phone.\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TextBlob(df['Reviews'][1].strip())\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.4833333333333334, subjectivity=0.7333333333333334, assessments=[(['real'], 0.2, 0.30000000000000004, None), (['amazing', '!'], 0.7500000000000001, 0.9, None), (['very', 'much', 'satisfied'], 0.5, 1.0, None)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\lib\\site-packages (from nltk) (3.4.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "simple_ratio=fuzz.ratio(\"Hello world\", \"Hello world!\")\n",
    "\n",
    "print(simple_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\lib\\site-packages (from python-Levenshtein) (40.6.2)\n",
      "Installing collected packages: python-Levenshtein\n",
      "  Running setup.py install for python-Levenshtein: started\n",
      "    Running setup.py install for python-Levenshtein: finished with status 'error'\n",
      "    Complete output from command c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\scripts\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\ayush\\\\AppData\\\\Local\\\\Temp\\\\pip-install-93kwoohf\\\\python-Levenshtein\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-record-px3hskmh\\install-record.txt --single-version-externally-managed --compile --install-headers c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\include\\site\\python3.7\\python-Levenshtein:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win32-3.7\n",
      "    creating build\\lib.win32-3.7\\Levenshtein\n",
      "    copying Levenshtein\\StringMatcher.py -> build\\lib.win32-3.7\\Levenshtein\n",
      "    copying Levenshtein\\__init__.py -> build\\lib.win32-3.7\\Levenshtein\n",
      "    running egg_info\n",
      "    writing python_Levenshtein.egg-info\\PKG-INFO\n",
      "    writing dependency_links to python_Levenshtein.egg-info\\dependency_links.txt\n",
      "    writing entry points to python_Levenshtein.egg-info\\entry_points.txt\n",
      "    writing namespace_packages to python_Levenshtein.egg-info\\namespace_packages.txt\n",
      "    writing requirements to python_Levenshtein.egg-info\\requires.txt\n",
      "    writing top-level names to python_Levenshtein.egg-info\\top_level.txt\n",
      "    reading manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "    writing manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "    copying Levenshtein\\_levenshtein.c -> build\\lib.win32-3.7\\Levenshtein\n",
      "    copying Levenshtein\\_levenshtein.h -> build\\lib.win32-3.7\\Levenshtein\n",
      "    running build_ext\n",
      "    building 'Levenshtein._levenshtein' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    \n",
      "    ----------------------------------------\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\scripts\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\ayush\\\\AppData\\\\Local\\\\Temp\\\\pip-install-93kwoohf\\\\python-Levenshtein\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-record-px3hskmh\\install-record.txt --single-version-externally-managed --compile --install-headers c:\\users\\ayush\\desktop\\virtualenvironments\\fuzzy\\include\\site\\python3.7\\python-Levenshtein\" failed with error code 1 in C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-install-93kwoohf\\python-Levenshtein\\\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "simple_ratio=fuzz.ratio(\"a\",\"b\")\n",
    "\n",
    "print(simple_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    " \n",
    "partial=fuzz.partial_ratio(\"Hello world\", \"bye world!\")\n",
    " \n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello world is an introductory phrase in programming', 90), ('Asia is the largest continent in the world', 86)]\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    " \n",
    "choices = [\"Hello world is an introductory phrase in programming\", \n",
    "           \"Game of throne is a movie\", \n",
    "           \"Albert Einstein developed the theory of relativity\", \n",
    "           \"Asia is the largest continent in the world\"]\n",
    " \n",
    "extract_all=process.extract(\"Hello world\", choices, limit=2)\n",
    " \n",
    "print(extract_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
