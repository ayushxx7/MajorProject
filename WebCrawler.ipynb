{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python code which crawls thru & downloads news headlines URL in excel format from major online news portals in India. With flexibility to incorporate below filters  \n",
    "● Keyword from News :  \n",
    "● Date  \n",
    "Hint : Youtube, How to scrape google web search and analyze headline sentiment with python.  \n",
    "Example : KEY WORDS “Haryana Cabinet Approves Delhi-Gurugram-SNB RRTS Corridor”  \n",
    "Date : 14th Feb 2019  \n",
    "What to do : Create a python crawler to identify above keyword associated news items available over internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /home/jupyterlab/conda/lib/python3.6/site-packages (0.15.3)\n",
      "Requirement already satisfied: bs4 in /home/jupyterlab/conda/lib/python3.6/site-packages (0.0.1)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/lib/python3.6/site-packages (2.21.0)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/jupyterlab/conda/lib/python3.6/site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/lib/python3.6/site-packages (from bs4) (4.7.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in /home/jupyterlab/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/jupyterlab/conda/lib/python3.6/site-packages (from beautifulsoup4->bs4) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob bs4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=haryana&tbs=cdr:1,cd_min:11/6/2018,cd_max:11/6/2018&tbm=nws\n",
      "/url?q=https://www.ndtv.com/india-news/khayal-acha-hai-manohar-khattars-swipe-at-aap-over-tweet-on-haryana-2007262&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIFCgAMAA&usg=AOvVaw32ZdXkBuVOOlOZyiPb35ct\n",
      "/url?q=https://www.indiatoday.in/mail-today/story/how-about-haryana-kejriwal-appeals-to-rahul-gandhi-1477582-2019-03-14&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIFygAMAE&usg=AOvVaw3JX1mfwpkSbHtVSB8aBNb4\n",
      "/url?q=https://www.hindustantimes.com/delhi-news/capital-wasting-300-cusecs-of-yamuna-water-haryana-tells-delhi-high-court/story-j0TaLM0Ns7Ktr3Xd4Zq0OO.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIICgAMAI&usg=AOvVaw0bccbQiJeEiux_xmGDmHc4\n",
      "/url?q=https://www.hindustantimes.com/lok-sabha-elections/lok-sabha-elections-2019-in-haryana-only-four-women-elected-mps-in-40-years/story-VFNB7m4dZqu1AgE1USFksK.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIIygAMAM&usg=AOvVaw1Vri7X5w3CfravdTVEJfP2\n",
      "/url?q=http://www.newindianexpress.com/nation/2019/mar/14/maneka-among-bjps-new-faces-in-haryana-1950911.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIJigAMAQ&usg=AOvVaw0yNFNHamROpJL7KnTAnY_2\n",
      "/url?q=https://www.news18.com/news/ivideos/why-haryana-govts-proposed-bill-threatens-aravalli-forest-range-2066531.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIIKSgAMAU&usg=AOvVaw2PH9-zzV3A4_m76O3cRpF0\n",
      "/url?q=https://www.business-standard.com/article/pti-stories/haryana-govt-probe-seeks-registration-of-cheating-case-against-ias-his-two-sportsperson-children-119031401011_1.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIILCgAMAY&usg=AOvVaw3iQ8xgD_xQTMlCgIiPgllb\n",
      "/url?q=https://www.business-standard.com/article/pti-stories/3-bodies-found-near-up-haryana-border-119031300429_1.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIILygAMAc&usg=AOvVaw3brBHB4O2xvj2Mix02y66N\n",
      "/url?q=https://www.thebetterindia.com/174549/haryana-holds-the-blueprint-for-improving-govt-schools-across-india-we-tell-you-why/&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIINCgAMAg&usg=AOvVaw0nttIZdDFMgK1DKCzR66hC\n",
      "/url?q=https://www.tribuneindia.com/news/chandigarh/haryana-forms-sit-in-morni-gang-rape-case/742657.html&sa=U&ved=0ahUKEwiyn6aqnYLhAhXEvI8KHdl5CVgQqQIINygAMAk&usg=AOvVaw3kghmnsoHVkmOJuEnzCk0O\n"
     ]
    }
   ],
   "source": [
    "class Analysis:\n",
    "    def __init__(self, term,date):\n",
    "        self.term = term\n",
    "        self.date = date\n",
    "        self.url = 'https://www.google.com/search?q={0}&tbs=cdr:1,cd_min:{1},cd_max:{2}&tbm=nws'.format(self.term,self.date,self.date)\n",
    "    def run(self):\n",
    "        response = requests.get(self.url)\n",
    "        print(self.url)\n",
    "        \n",
    "        #print(response.text)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "#         print(soup.a)\n",
    "        headline_results = soup.find_all('div', class_='g')\n",
    "        for headline in headline_results:\n",
    "            a = headline.find('a')\n",
    "            href = a['href']\n",
    "            print(href)\n",
    "#             print(headline.find('a'))\n",
    "            \n",
    "#             print(type(a))\n",
    "            print(a['href'])\n",
    "        #headline_results = soup.find_all('a class=\"l\"')\n",
    "        #headline_results = soup.find_all(text = 'a class=\"l')\n",
    "#         headline_results = soup.select('.r a')\n",
    "#         print(headline_results)\n",
    "        #print(type(headline_results))\n",
    "#         df = pd.DataFrame(headline_results)\n",
    "#         print(df)\n",
    "#         df.to_excel('aish.xlsx')\n",
    "        #for link in soup.find_all('a'):\n",
    "            #print(link.get('href'))\n",
    "        #for h in headline_results:\n",
    "            #print(h)\n",
    "        \n",
    "        #for h in headline_results:\n",
    "            #h = h[h.find('<a href=\"/url?q=') + len('<a href=\"/url?q='):h.find('&amp')]\n",
    "\n",
    "        #li = list()\n",
    "        \n",
    "        #for h in headline_results:\n",
    "            #print(h.get('href'))\n",
    "            \n",
    "        #for h in headline_results:\n",
    "            #li.append(h.get('href'))\n",
    "            \n",
    "        #for i in li:\n",
    "            #print(li)\n",
    "          \n",
    "A = Analysis('haryana', '11/6/2018')\n",
    "A.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
